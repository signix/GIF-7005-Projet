{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5f25db",
   "metadata": {},
   "source": [
    "# Prédiction de l’achalandage des stations Bixi\n",
    "\n",
    "Ce projet vise à prédire le taux d’entrées et de sorties par tranche horaire dans les stations Bixi à l’aide de plusieurs modèles :\n",
    "\n",
    "- **STGNN (Spatio-Temporal Graph Neural Network)** : réseau neuronal à graphes spatio-temporels, stations comme nœuds, arêtes basées sur la distance ou le temps de déplacement.\n",
    "- **LSTM (Long Short-Term Memory)** : réseau neuronal récurrent adapté aux séries temporelles.\n",
    "- **Modèle statistique** : régression ou analyse classique pour servir de baseline.\n",
    "\n",
    "Nous comparerons la performance de ces modèles sur les données d’achalandage.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Importation des librairies et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cf9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# Pour apprentissage\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#from torch.utils.data import DataLoader, Dataset\n",
    "# Pour LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "# Pour le modèle statistique\n",
    "# import statsmodels.api as sm\n",
    "# Pour le graphe\n",
    "# import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953819d6",
   "metadata": {},
   "source": [
    "## 2. Exploration et préparation des données\n",
    "\n",
    "- Nettoyage et visualisation\n",
    "\n",
    "- Construction du graphe des stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e37f89-8863-4fa5-83d9-f7a10d77bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        end_date  end_station_code  \\\n",
      "start_date          start_station_code                               \n",
      "2018-08-23 21:00:00 6184                      14                14   \n",
      "2018-09-04 17:00:00 6184                      12                12   \n",
      "2018-08-03 11:00:00 6131                      12                12   \n",
      "2018-07-19 23:15:00 6155                      12                12   \n",
      "2018-06-27 17:30:00 6184                      11                11   \n",
      "...                                          ...               ...   \n",
      "2018-11-15 23:45:00 6155                       1                 1   \n",
      "                    6158                       1                 1   \n",
      "                    6164                       1                 1   \n",
      "                    6169                       1                 1   \n",
      "2018-04-10 12:30:00 6237                       1                 1   \n",
      "\n",
      "                                        duration_sec  \n",
      "start_date          start_station_code                \n",
      "2018-08-23 21:00:00 6184                          14  \n",
      "2018-09-04 17:00:00 6184                          12  \n",
      "2018-08-03 11:00:00 6131                          12  \n",
      "2018-07-19 23:15:00 6155                          12  \n",
      "2018-06-27 17:30:00 6184                          11  \n",
      "...                                              ...  \n",
      "2018-11-15 23:45:00 6155                           1  \n",
      "                    6158                           1  \n",
      "                    6164                           1  \n",
      "                    6169                           1  \n",
      "2018-04-10 12:30:00 6237                           1  \n",
      "\n",
      "[303263 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/merged2018_reduced_dataset.csv\", parse_dates=['start_date', 'end_date'])\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "# print(df.get(0))\n",
    "df_grouped = df.groupby([ pd.Grouper(key=\"start_date\", freq=\"15min\"),\n",
    "                 pd.Grouper('start_station_code')\n",
    "                 ]).count()\n",
    "\n",
    "print(df_grouped.sort_values(by=['end_date'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544560c",
   "metadata": {},
   "source": [
    "## 3. Modélisation\n",
    "\n",
    "### 3.1 Modèle statistique (baseline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e14061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olidr\\AppData\\Local\\Temp\\ipykernel_10268\\3808528892.py:4: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df['slot_15'] = df['end_date'].dt.floor('15T') # Tronquer à l'intervalle de 15 minutes le plus proche\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.4473305597783349\n",
      "RMSE: 0.6870355561229784\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/merged2018_reduced_dataset.csv\") \n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df['end_date'] = pd.to_datetime(df['end_date'])\n",
    "df['slot_15'] = df['end_date'].dt.floor('15T') # Tronquer à l'intervalle de 15 minutes le plus proche\n",
    "\n",
    "# Calcul des arrivées par station et par intervalle de 15 minutes\n",
    "arrivals = (\n",
    "    df\n",
    "    .groupby(['end_station_code', 'slot_15'])\n",
    "    .size()\n",
    "    .reset_index(name='arrivals')\n",
    ")\n",
    "\n",
    "# Calcul de la moyenne historique des arrivées par station, jour de la semaine, heure et minute\n",
    "arrivals['dow'] = arrivals['slot_15'].dt.dayofweek   # 0=lundi\n",
    "arrivals['hour'] = arrivals['slot_15'].dt.hour     # 0-23\n",
    "arrivals['minute'] = arrivals['slot_15'].dt.minute   # 0,15,30,45\n",
    "\n",
    "# Calcul de la moyenne historique des arrivées\n",
    "historical_mean = (\n",
    "    arrivals\n",
    "    .groupby(['end_station_code', 'dow', 'hour', 'minute'])['arrivals']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'arrivals': 'mean_arrivals'})\n",
    ")\n",
    "# Fusion des données réelles avec les moyennes historiques\n",
    "pred = arrivals.merge(\n",
    "    historical_mean,\n",
    "    on=['end_station_code', 'dow', 'hour', 'minute'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Calcul des métriques MAE et RMSE\n",
    "mae = mean_absolute_error(pred['arrivals'], pred['mean_arrivals'])\n",
    "rmse = np.sqrt(mean_squared_error(pred['arrivals'], pred['mean_arrivals']))\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79206a3f",
   "metadata": {},
   "source": [
    "### 3.2 Modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6aa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n",
      "TensorFlow version: 2.20.0\n",
      "Num GPUs Available: 0\n",
      "cpu\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olidr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 2/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 2/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 3/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 3/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 4/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 4/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 5/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 5/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 6/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 6/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 7/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 7/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 8/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 8/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 9/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 9/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 10/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 10/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 11/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 11/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 12/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 12/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 13/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 13/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 14/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 14/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 15/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 15/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 16/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 16/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 17/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 17/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 18/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 18/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 19/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 19/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 20/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 20/20\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "MAE LSTM: 0.599482371103625\n",
      "RMSE LSTM: 0.7229003745895571\n",
      "MAE LSTM: 0.599482371103625\n",
      "RMSE LSTM: 0.7229003745895571\n"
     ]
    }
   ],
   "source": [
    "# Modèle LSTM pour la prédiction des arrivées par station\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# Exemple : prédire pour une station donnée (ex : 6169)\n",
    "station_id = 6169\n",
    "df_station = arrivals[arrivals['end_station_code'] == station_id].sort_values('slot_15')\n",
    "\n",
    "# Série temporelle des arrivées\n",
    "series = df_station['arrivals'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler()\n",
    "series_scaled = scaler.fit_transform(series)\n",
    "\n",
    "# Création des séquences pour LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 96  # 24h si 15min pas step\n",
    "X, y = create_sequences(series_scaled, seq_length)\n",
    "\n",
    "# Split train/test\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Modèle LSTM\n",
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(seq_length, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Entraînement\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Prédiction et inverse transform\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Évaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "print('MAE LSTM:', mae)\n",
    "print('RMSE LSTM:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52f3ec",
   "metadata": {},
   "source": [
    "### 3.3 Modèle STGNN (Spatio-Temporal Graph Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc87d9",
   "metadata": {},
   "source": [
    "## 4. Comparaison des performances\n",
    "\n",
    "- Métriques : RMSE, MAE, etc.\n",
    "- Visualisation des résultats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
